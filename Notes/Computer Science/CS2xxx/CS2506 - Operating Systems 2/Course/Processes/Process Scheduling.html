<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Process Scheduling</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      div.line-block{white-space: pre-line;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="/Users/Noel/Developer/Projects/Github Page/Notes/note-style.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="scheduling" class="level2">
<h2>Scheduling</h2>
<p>Historically, the CPU is allocated to one process until its completion (batch processing). After this period of time, the CPU was time-shared by multiple processes ready to execute. As the CPU is time-shared, processes compete for the next available time slot.</p>
<p>The scheduler is the kernel process that implements an algorithm that decides which process gets the CPU next.</p>
<ul>
<li>The scheduling process needs to be fair to all processes.</li>
<li>Processes ready to execute are organised in a queue (the ready to execute queue), from which the scheduler selects the next one.</li>
<li>A process takes control of the CPU by having its state restored, after the state of the previous process is saved.</li>
<li>A process can have control of the CPU for at most one time slice (represented by <code>tau</code> seconds).</li>
<li>The execution time of the scheduler should be very short, as it needs to operate just on the boundary of a time slice.
<ul>
<li>The execution time of the scheduler shouldn’t depend on the number of processes to execute. (Should be a constant-time operation.)</li>
<li>Uses a binary vector with one flag per process (in Linux) to ensure this.</li>
</ul></li>
</ul>
<section id="scheduling-strategies" class="level3">
<h3>Scheduling Strategies</h3>
<section id="first-come-first-served-fcfs-a.k.a.-round-robin" class="level4">
<h4>First-Come First-Served (FCFS a.k.a. Round Robin)</h4>
<ul>
<li>Processed are getting CPU control in their order in the queue.</li>
<li>One possibility is to have control of the CPU until the process finishes – non-preepmtive execution. This may lead to starvation of other processes.</li>
<li>So the best solution is to time-share the CPU. [more here]</li>
</ul>
<section id="example-shortest-process-first" class="level5">
<h5>Example: shortest process first</h5>
<p>If the CPU isn’t time-shared (and so is batch-processed), the order in which processes are scheduled is important. * Processes can be ordered according to their execution time. * If processes get control in the increasing value of their execution time, the average turnaround time is better than in the random order. * turnaround time is the waiting time + the execution time * average turnaround time is the sum of turnaround times for each process, divided by the number of them * important for admin – gives a measure of how long a process will stay in the system until its completion * the time consumed from the moment the process is ready for execution until its completion.</p>
<p>Say you have four processes with their completion times in brackets: a(50), b(60), c(20) and d(45).</p>
<p>In that order, the turnaround times will be: 50, 110, 130, 175.</p>
<p>The average turnaround is then 465/4.</p>
<p>If you order them as shortest-first, the turnaround times become: a(115), 175, 20, d(65).</p>
<ul>
<li>To do this though, you need to know the execution times of all the processes, and you need to know that they’ll all start at the same time.
<ul>
<li>These characteristics exist in embedded systems.</li>
</ul></li>
</ul>
</section>
</section>
<section id="priority-scheduling" class="level4">
<h4>Priority Scheduling</h4>
<ul>
<li>processes are different, some interactive and some computationally demanding.
<ul>
<li>The time for some is dominated by I/O, and for some is dominated by CPU time.</li>
<li>A process with no I/O can’t be switched to a blocked state(?)</li>
</ul></li>
</ul>
<p>So we assigned a priority to processes. This is an integer – the lower the value, the higher the priority.</p>
<ul>
<li>kernel processes have higher priority than user processes</li>
<li>give fast, interactive processes higher priorities</li>
<li>historically, the priority was assigned in advance, but nowadays processes can have their priorities changed at runtime
<ul>
<li>this can happen when a process has to wait a long time for an I/O operation with a hard drive
<ul>
<li>The priority is increased once the operation is finished.</li>
</ul></li>
<li>This can also happen with a CPU-intensive operation
<ul>
<li>If it gets a couple of time slices to itself, the priority may be decreased to allow access for other processes</li>
</ul></li>
</ul></li>
</ul>
<section id="multilevel-feedback-queues" class="level5">
<h5>Multilevel Feedback Queues</h5>
<ul>
<li>Several queues, each associated with a priority level. Initially each process gets a priority that puts it on a certain level.</li>
<li>After consuming each time-slice, the process priority is lowered to the next level, until it reaches the lowest acceptable priority. At that level, the strategy is round-robin.</li>
<li>[more here]</li>
<li>Generally we have at most 4-16 queues/priority levels.
<ul>
<li>With sensors and embedded systems, we have at most 4.</li>
</ul></li>
<li>For each process, we have a highest acceptable priority and a lowest acceptable priority.</li>
</ul>
<section id="a-process-for-power-management" class="level6">
<h6>A Process for Power Management</h6>
<p>Many systems have an idle process, which has the lowest priority. When there is no other process to execute, the CPU is given to the idle process, which switches the system into sleep state(s), to manage power consumption.</p>
<p>The idle process implements the kernel power policy manager, which owns the decision-making and the set of rules used to determine the appropriate frequency/voltage operating state. It may make decisions based on several inputs, such as end-user power-policy, processor utilisation, battery level, or thermal conditions and events.</p>
<p>The processor driver is used to make actual state transitions on the kernel power policy manager’s behalf.</p>
<p>Note the idle process can be quite complex, because of the amount of input parameters. Also a sleep state wouldn’t involve just the CPU, but also other hardware components.</p>
<p>The system needs to switch back to the active state when there are new processes.</p>
</section>
</section>
<section id="mfq-cont." class="level5">
<h5>MFQ (cont.)</h5>
<p>As well as the priority changing at runtime, there can be a different time-slice size for each priority level, where low-priority levels get much larger time slices, as they are tasks which take longer. This is often increased exponentially for lower priority levels, e.g. the time-slice for level i might be q*2<sup>i</sup></p>
<p>If a process didn’t complete at level i, then its priority is lowered and its time-slice is increased.</p>
<section id="two-level-scheduling" class="level6">
<h6>Two-Level Scheduling</h6>
<p>Sometimes, there are too many processes that can’t fit in main memory at the same time. So some will have be stored on the disk. But the process of restoring the process in the main memory while others are saves on the disk is time-consuming – this can lead to thrashing.</p>
<p>One solution is to use two-level scheduling:</p>
<ul>
<li>a higher-level, long-term scheduler that runs more slowly (maybe every n time-slices) will select the subset of processes resident in the main memory</li>
<li>processes in the main memory are then managed by a different scheduler, lower-level and short-term</li>
</ul>
<p>99% of the time, only the short-term scheduler is running – the other is only launched when the system is struggling.</p>
</section>
<section id="real-time-scheduling" class="level6">
<h6>Real-time Scheduling</h6>
<ul>
<li>Keeps doing the same thing forever until you switch it off.</li>
<li>Event-driven systems – system responds to events signalled by interrupts.</li>
<li>Mostly short processes</li>
<li>Have to meet deadlines
<ul>
<li>e.g. <code>a</code> has to happen every 400 time units, <code>b</code> every 500 time units, <code>c</code> every 700 units, <code>d</code> every 900 units.</li>
</ul></li>
</ul>
<p>Say we have those processes, and each will execute in less than the time slice of 100 time units.</p>
<p>In general we can pick the ones with the earliest deadlines first. When things have the same earliest deadline, we need another priority to choose which one. Could be whichever one had control longest ago.</p>
</section>
<section id="multi-core-systems" class="level6">
<h6>Multi-Core Systems</h6>
<ul>
<li>A package is two cores and one L2 cache.</li>
<li>On each core we can have processes that are totally independent of one another, or processes that belong to the same application.
<ul>
<li>If they belong to the same application, then they share data.</li>
</ul></li>
<li>We can also have different threads of the same process.
<ul>
<li>These share everything (code, data, etc)</li>
<li>All of this shared stuff needs to be stored in L2.</li>
</ul></li>
</ul>
<p>In hardware, L2 is split into a number of blocks, and access is by a grid. Cores can’t access the same block at the same time. So they can’t access the exact same data at the same time.</p>
<p>We can’t eliminate contention, but we can reduce it by designing well.</p>
<p>First scheduling policy: group scheduling</p>
<ul>
<li>Put processes together that share data (and possibly code) - these processes are said to have affinity for one another.</li>
</ul>
<p>Many multi-core systems are mobile devices powered by batteries, so energy usage is important and must be managed. With multiple packages, we have to decide at any time whether we should use all packages, or keep one in a sleep state to save energy. If execution time is not important, the scheduler will choose to use just one package, and won’t turn on the second. This is the second scheduler policy.</p>
<p>All cores don’t have to be loaded to the same degree – some can be overloaded and some can be underloaded. We can define an average load, which is the boundary between under- and over-loaded.</p>
<p>If one core is overloaded and one is underloaded, we want to move processes from one to the other – this is load balancing. This is a new attribute of the scheduler specific to multi-core systems.</p>
<p>What is load? We can define it as the amount of time spent busy in a certain period of time.</p>
<p>The third scheduler policy is domain scheduling.</p>
<ul>
<li>This is a hardware perspective, concerned with resources.</li>
</ul>
<p>A domain is a group of cores that share the same specifications and share the same load-balancing and scheduling policies.</p>
<p>We can create hierarchies of domains. Say level 1 is any package used alone in a four-package system. Say level two is two packages used at once, and level 3 is all packages used.</p>
<ul>
<li>For level 1 we have 4 domains
<ul>
<li>Level 1 is a two-core system</li>
</ul></li>
<li>For level 2 we have 2 domains
<ul>
<li>Level 2 is a four-core system</li>
</ul></li>
<li>For level 3 we have 1 domain
<ul>
<li>Level 3 is an 8-core system</li>
</ul></li>
</ul>
<p>We can have different scheduling policies then for each domain.</p>
<ul>
<li>For level 3 we might say that if a package has low load, we’ll switch it off and distribute tasks to other processes
<ul>
<li>This would be an energy-saving policy</li>
</ul></li>
<li>For level 2 we might use load-balancing for a policy (balance the load across cores in each domain)
<ul>
<li>We can have different policies in different domains of the same level</li>
</ul></li>
<li>For level 1 we might say “if exec: move to another core” (this also mentioned for level 3)
<ul>
<li>Alternatively, on one particular domain we might pair processes that are CPU-intensive (but use little memory) on one core and processes that are memory-intensive (but use little CPU) on the second core.</li>
</ul></li>
</ul>
<p>With this process we’re creating virtual machines:</p>
<ul>
<li>1 with 8 cores</li>
<li>2 with 4 cores each</li>
<li>4 with 2 cores each</li>
</ul>
<p>The scheduler has prior info about processes:</p>
<ul>
<li>Memory access patterns</li>
<li>Resources that are required</li>
</ul>
<p>It gets this info from previous executions (collects runtime info), or it can use heuristics to anticipate resource usage.</p>
</section>
</section>
</section>
</section>
</section>
<section id="scheduling-cont." class="level1">
<h1>Scheduling (cont.)</h1>
<p>Different operating systems may implement these scheduling principles in different ways, or may not implement all of them. Group and domain scheduling are popular.</p>
</section>
<section id="unix" class="level1">
<h1>UNIX</h1>
<section id="primitive-calls" class="level2">
<h2>Primitive calls</h2>
<ul>
<li><code>fork()</code> creates a new process that is an exact copy of the parent process</li>
<li><code>exec()</code> replaces the code of the existing program with a new one</li>
<li><code>exit()</code> allows a process to voluntarily terminate</li>
<li><code>kill()</code> allows a process with appropriate privilege to terminate another process</li>
<li><code>wait()</code> allows a process to pause until a child process has finished, and pick up its exit status</li>
</ul>
</section>
<section id="process-states" class="level2">
<h2>Process States</h2>
<p>In addition to running, blocked, and ready, there are a few additional states:</p>
<ul>
<li><code>SSLEEP</code> – a blocked state where the process cannot be awakened by a signal</li>
<li><code>SWAIT</code> – a blocked state that allows the process to be awakened to handle a signal</li>
<li><code>SRUN</code> – Identifies running and ready processes. The <code>u</code> variable contains the process table info of the currently running process</li>
<li><code>SIDL</code> – a process is created but the copy of its parent’s memory space can not be done immediately</li>
<li><code>SZOMB</code> […]</li>
<li>[…]</li>
</ul>
</section>
<section id="process-table" class="level2">
<h2>Process Table</h2>
<p>The process table uses some flags to record the status of the process in respect to memory (the process is in memory or swapped out) and tracing.</p>
<p>The process table is divided in two:</p>
<ul>
<li>The first part is an array of structures as part of the kernel space. These structures hold admin info, state info, id, scheduling info.</li>
<li>The other part is data not needed when the process is swapped out, and is part of the user space. User structures are swapped along with the rest of the process’ memory space – this is to preserve space.</li>
</ul>
</section>
<section id="scheduling-1" class="level2">
<h2>Scheduling</h2>
<p>The scheduler uses process priorities. The actual scheduling code is in the context</p>
<ul>
<li>priority is dynamically updated:
<ul>
<li><code>p = min(127, c/(16 + 100 + n))</code></li>
<li><code>n</code> is a parameter called nice – if this increases, the priority lowers</li>
</ul></li>
<li>two-level scheduler</li>
</ul>
</section>
</section>
<section id="tinyos" class="level1">
<h1>TinyOS</h1>
<p>Very simple compared to what we’ve seen with a general purpose computer. There are many other OSes for sensors, but this one is interesting because it shows how simple and basics things can be.</p>
<p>It’s also very similar to OSes for internet of things devices.</p>
<p>Tasks, events and commands execute in the context of the frame and operate on its state.</p>
<ul>
<li>CPU typically 8 or 16 bits</li>
<li>Processor typically 4 MHz</li>
<li>Memory in KB</li>
<li>No virtual memory, segmentation, or paging</li>
</ul>
<p>Energy has to be managed as tightly as possible.</p>
<ul>
<li>Computation has to be very fast</li>
<li>Communication has to be done as seldom as possible.</li>
</ul>
<p>We have sensors deployed in the environment, which create sensor networks that are used to push sample data towards a server. The server does storage.</p>
<p>Each sensor works as a router, as well as doing its sampling work.</p>
<p>The OS must have a footprint of KBs or less in main memory. Remember the memory here is just a plain location, addressed simply. No files, no virtual memory.</p>
<p>Modular system.</p>
<p>This is an OS for tiny sensors that provides a set of system SW components. Only the necessary parts of the OS are compiled with the application, meaning each application is built into the OS.</p>
<p>An application wires OS components together with application-specific components – a complete system consists of a scheduler and a graph of components.</p>
<p>A component has four interrelated parts:</p>
<ul>
<li>A set of command handlers
<ul>
<li>commands are input</li>
<li>generally target tasks</li>
</ul></li>
<li>A set of event handlers
<ul>
<li>events are input</li>
</ul></li>
<li>A fixed-size frame</li>
<li>A bundle of tasks</li>
</ul>
<p>The component may also be a source of events or of commands.</p>
<p>A task is not a process – we don’t have the concept of a process here.</p>
<p>A task defines a computation that corresponds to some function.</p>
<p>E.g.:</p>
<ul>
<li><code>get ADC data</code> – get data from the ADC (from the sensor)</li>
<li><code>send packet</code> – for communication</li>
</ul>
<p>At most 10/20 instructions.</p>
<ul>
<li>All tasks execute until completion.
<ul>
<li>unless there is an event</li>
<li>events interrupt tasks that are currently in execution
<ul>
<li>control is taken by that event handler</li>
</ul></li>
</ul></li>
</ul>
<p>Event handlers do very simple things. Generally they “post” tasks – pushing them into the ready queue. The only other things they do are small things, e.g. incrementing a counter or assigning a local variable.</p>
<ul>
<li>events can be interrupted by other events</li>
</ul>
<p>When the ready queue is empty, the core is switched to a sleep state, but the sensors aren’t, as they still need to act as a router.</p>
<p>The whole system is a graph of components.</p>
<ul>
<li>some of these are OS components
<ul>
<li>timer, radio, routing, etc.</li>
</ul></li>
<li>some are application-specific
<ul>
<li>sensors and specific processing</li>
</ul></li>
</ul>
<p>Commands can’t trigger events, because that could create cycles.</p>
<p>If a task is posted but there’s no space in the ready queue (in TinyOS v1), it fails. Since the queue is a shared resource, one misbehaving component can ruin everything.</p>
<p>In version 2, now tasks have priorities, and the scheduler can run earliest deadline first. The order of execution can be changed.</p>
<p>One byte of state is allocated per task, this gives us 255 possible priority levels – it’s assumed there’s less than 255 tasks in the system.</p>
<p>A basic post will fail if and only if the task has already been posted and has not started execution.</p>
<section id="tinyos-timer" class="level2">
<h2>TinyOS Timer</h2>
<p>Different sensors can have very different sampling periods (a few seconds, a few hours).</p>
</section>
<section id="field-monitor-application" class="level2">
<h2>Field Monitor Application</h2>
<p>Sampling takes time, and with the task/event structure, the CPU doesn’t have to be waiting for the data. The task can be <code>get ADC data; return immediately</code>, and then the CPU will send the command to the ADC and then continue with the next task. When the data is ready in the ADC, an event will be sent to tell the CPU that the data is ready.</p>
<p>Remember that energy consumption for communicating (e.g. by radio) is orders of magnitude greater than energy consumption in the rest of the system.</p>
<p>The units onscreen are all software, except the RFM, the ADC, and the HWClock. As a designer, we wouldn’t see these as hardware but as components that we can use in our application.</p>
<section id="active-messages" class="level3">
<h3>Active Messages</h3>
<p>The message includes the destination handler and nothing else (besides the message itself). This keeps things simple.</p>
<p>We don’t have to transport layer, we don’t have the protocol stack (IP, TCP) from the internet.</p>
</section>
<section id="main" class="level3">
<h3>Main</h3>
<p>The main is just for initial setup (e.g. variable initialisation), it’s not involved after that, so no events ever need to go to the main.</p>
<p>Note there’s no monitoring of the sensors to make sure they’re ok and still working.</p>
</section>
</section>
</section>
<section id="android" class="level1">
<h1>Android</h1>
<p>The concept was that the handheld is the new PC, so we need a complex general purpose OS.</p>
<p>However, android also includes non-OS things like middleware and applications. Applications like the phone, the messages, etc. are basic and built-in.</p>
<p>He’ll focus on activity and intent and how activities are managed in Android on Monday.</p>
</section>
<section id="android-1" class="level1">
<h1>Android</h1>
<ul>
<li>kernel, middleware services, applications</li>
<li>(extends beyond a classic operating system)</li>
<li>has its own JVM (Dalvik VM)</li>
<li>shares components and data among applications</li>
<li>applications reuse components from one another
<ul>
<li>a process may skip some components</li>
<li>execution flow can jump from one process to another
<ul>
<li>this is inter-process communication (IPC)</li>
<li>(possibly just on the same component)</li>
</ul></li>
</ul></li>
<li>this is an event-driven operating system, rather than a general-purpose operating system
<ul>
<li>for general-purpose system, all interaction is by commands</li>
<li>for this, the operating system may respond to user events if it has the resources</li>
<li>[check difference between general-purpose OS and event-driven OS]</li>
</ul></li>
<li>applications have a non-visible part to their lifecycle</li>
</ul>
<section id="android-applications" class="level2">
<h2>Android Applications</h2>
<p>Applications don’t have a single entry point for everything in the application (no <code>main()</code> function, for example). They have components that the system can instantiated and run as needed.</p>
<p>An <em>intent</em> is an amalgamation of ideas such as windowing messages, actions, inter-process communication, publish/subscribe models and application registries.</p>
<p>Intents define intention to do some work (e.g. broadcast a message, start a service, launch an activity, dial a phone number, answer a call). They can also be used by the system to notify the application of specific events (e.g. arrival of a text message).</p>
<p><em>Views</em> are UI elements that can be used to create a user interface.</p>
<p>An <em>activity</em> is a UI concept. Usually it represents a single screen in the application. It can contain one or more views.</p>
<p><em>Content providers</em> allow to expose data to sharing by multiple applications.</p>
<p>A <em>service</em> is a background process, either local or remote.</p>
</section>
<section id="lifecycle" class="level2">
<h2>Lifecycle</h2>
<p>The android application lifecycle is managed by the system based on the user needs, available resource, etc.</p>
<p>The system decides if an application can be loaded or it is paused or stopped.</p>
<p>The activity currently used (has visibility) get higher priority, while an activity not visible can be killed to free resources.</p>
<p>Each android application runs in a separate process which hosts its own virtual machine. [dynamically changing priority, etc]</p>
<ul>
<li><code>onCreate()</code>
<ul>
<li>-&gt; <code>onStart()</code></li>
</ul></li>
<li><code>onStart()</code>
<ul>
<li>-&gt; <code>onResume()</code></li>
</ul></li>
<li><code>onResume()</code>
<ul>
<li>-&gt; Running -&gt; <code>onPause()</code>
<ul>
<li>another activity comes in front of the activity</li>
</ul></li>
</ul></li>
<li><code>onPause()</code>
<ul>
<li>-&gt; <code>onResume()</code>
<ul>
<li>the activity comes to the foreground</li>
</ul></li>
<li>-&gt; <code>onStop()</code>
<ul>
<li>the activity is no longer visible</li>
</ul></li>
<li>-&gt; killed -&gt; <code>onCreate()</code>
<ul>
<li>other applications need memory</li>
<li>user navigates back to the activity</li>
</ul></li>
</ul></li>
<li><code>onStop()</code>
<ul>
<li>-&gt; <code>onDestroy()</code></li>
<li>-&gt; <code>onRestart()</code>
<ul>
<li>the activity comes to the foreground</li>
</ul></li>
<li>-&gt; killed -&gt; <code>onCreate()</code></li>
</ul></li>
<li><code>onRestart()</code>
<ul>
<li><code>onStart()</code></li>
</ul></li>
<li><code>onDestroy()</code>
<ul>
<li>shut down</li>
</ul></li>
</ul>
<p>If a user interacts with an application, that application gets the highest priority.</p>
</section>
<section id="tasks" class="level2">
<h2>Tasks</h2>
<p>With IPC (e.g. we want to display a street map from GPS), we are starting a task following the user’s commands.</p>
<p>A task is a sequence of activities that make the execution flow.</p>
<p>The fact that you’re allowed go from one process to another is very different from general purpose OSes.</p>
<section id="task-stack" class="level3">
<h3>Task Stack</h3>
<p>A task is a stack of activities. The top of the stack contains the current activity.</p>
<p>If a new task is started, the previous one is saved and switched to the background. So the stack is preserved, but is not the running task. It’s still in the memory. We may have more than one stack that’s in the background at once. Activities in the stack are never re-arranged, just pushed and popped.</p>
<p>If the system needs resources, it can delete activities from the stacks, or delete whole stacks.</p>
<p>This is how different applications are kept available to the user.</p>
</section>
</section>
</section>
<section id="linux" class="level1">
<h1>Linux</h1>
<p>Processes and threads are tasks. (Different from android tasks).</p>
<section id="system-calls" class="level2">
<h2>System Calls</h2>
<p>There are nearly 300 system calls, many related to process management:</p>
<ul>
<li><code>fork()</code></li>
<li><code>vfork()</code> is a variation on <code>fork()</code> that eliminates the copy of the parent memory space in the case where <code>fork()</code> is quickly followed by an <code>exec()</code> call. The child uses the parent memory space until invoking <code>exec()</code>. The parent is suspended this time.</li>
<li><code>clone()</code> allows specification of which of the parent’s resources are to be shared with the child and which are to be copied.
<ul>
<li>specification is with clone flags</li>
</ul></li>
<li><code>execve()</code> allows a process to specify a program to begin running in place of the current one.</li>
<li>[more here]</li>
</ul>
</section>
<section id="scheduler-calls" class="level2">
<h2>Scheduler Calls</h2>
<ul>
<li><code>sched_setscheduler()</code> allows a process with enough privileges (system) to change the policy and priority level the scheduler uses for the specified process […]</li>
</ul>
</section>
<section id="process-state" class="level2">
<h2>Process State</h2>
<ul>
<li>TASK_RUNNING</li>
<li>TASK_INTERRUPTIBLE</li>
<li>TASK_UNINTERRUPTIBLE</li>
<li>TASK_STOPPED</li>
<li>TASK_TRACED</li>
<li>TASK_ZOMBIE
<ul>
<li>still consuming resources?</li>
</ul></li>
<li>TASK_DEAD</li>
</ul>
</section>
<section id="process-creation" class="level2">
<h2>Process Creation</h2>
<p><code>fork()</code>, <code>vfork()</code>, and <code>clone()</code> all call <code>do_fork()</code>.</p>
<ul>
<li>if it’s <code>vfork()</code>, the parent needs to be suspended
<ul>
<li>the parent will return to ready when the child calls <code>exit()</code> or <code>exec()</code></li>
</ul></li>
<li>the child can be in a stopped or ready state initially</li>
<li><code>alloc_pid()</code> is called to give the child a process id
<ul>
<li>this will try to use <code>last_pid + 1</code>, but it will have to check that it’s not in use</li>
<li>this searching could be very slow, so a bit vector is used – the first 0 that’s found gives the new PID</li>
</ul></li>
</ul>
<p>The parent can return to ready if the call came from <code>fork()</code> or <code>clone()</code>.</p>
</section>
</section>
<section id="linux-scheduler" class="level1">
<h1>Linux Scheduler</h1>
<p>This gives preference to interactive processes and processes with lower <code>nice</code> values.</p>
<ul>
<li>two multilevel feedback queues – one for active processes, one for expired processes</li>
<li>uses a bitmap to quickly determine which queue is the highest priority nonempty one […]</li>
</ul>
<p>Two classes of process:</p>
<ul>
<li>real-time (RT)
<ul>
<li>these are scheduled according to SCHED_FIFO or SCHED_RR (round robin).</li>
<li>first-in-first-out processes will always complete</li>
<li>round-robin ones will return but with the same priority</li>
<li>these are processes which generally don’t use a full time-slice</li>
</ul></li>
<li>time-sharing
<ul>
<li>these work as described before</li>
</ul></li>
</ul>
<section id="priorities" class="level2">
<h2>Priorities</h2>
<p>Real-time processes have a static priority in the range [0, 99].</p>
<p>Time-sharing processes have a priority in the range [-20, 19]. Internally they are scaled to the range [100, 139].</p>
<p>Smaller values correspond to higher priorities.</p>
<p>Remember each priority level is a queue. If a real-time process from a round-robin queue doesn’t complete, it’ll return to the end of the queue it came from.</p>
<p>[check all of this bit, lots of info here]</p>
<p>If there are no more time-sharing processes in the active structure, the time-sharing parts of the active and expired structures are swapped.</p>
<p><code>tick()</code> is a system call which checks what a core is running.</p>
<ul>
<li>if the core is idle, it might rebalance the load from other cores</li>
<li>if the current process is from the expired set, this is considered an error
<ul>
<li>this can happen if there are no active processes left and no swap occurred to swap the active processes with the expired processes</li>
<li>it’s an error because we only want active processes to have controller</li>
</ul></li>
</ul>
</section>
</section>
<section id="the-linux-scheduler" class="level1">
<h1>The Linux Scheduler</h1>
<ul>
<li>runs in constant time because it uses a bit vector (where each bit is set if and only if there are processes waiting in the corresponding queue) to check which process to run</li>
</ul>
</section>
</body>
</html>
